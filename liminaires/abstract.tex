\begin{abstract}
Global transcriptomic analysis consists of quantifying all the transcripts expressed in a sample, for a given time, individual and biological condition. Recent bulk RNA-Seq analyses enable automatic processing of increasing transcriptomic volumes, at a high throughput, and with decreasing analysis costs. In particular, these technologies have led to a better understanding of the biological processes involved in the development of complex and heterogeneous diseases, contributing to the development of personalised medicine.


As a result, a growing part of pre-clinical research to identify new therapeutic targets consists of recovering the mechanistic processes involved in the differential response to a treatment by the observed differences in transcriptome expression profiles across individuals. The fluctuations observed stem from nested interactions between technical and biological factors, some of them not explicitly accounted for the transcriptome (metabolome, genomics, etc.) or unobserved. It may therefore be useful to introduce a latent variable in an attempt to explain hidden biological mechanisms. On the other hand, the exploratory possibilities offered by transcriptome analysis methods are hindered by their very nature. By measuring the expression of a set of genes at a global scale, they veil the intrinsic heterogeneity of biological environments, by averaging the transcriptomic measurements expressed by multiple cell populations.


In this PhD manuscript, we propose three major contributions to overcome the inherent limitations of these methods. The first part presents an industrial transcriptomic analysis pipeline, as a suite of R in-house software packages, and aimed at homogenising classic differential and enrichment analysis as well as internal data management and pre-processing practices. The second part introduces a benchmark of R packages, all of them implementing the EM algorithm to infer the parameters of Gaussian mixture models. We then displayed a collobrative work related, in which we set up an unsupervised stratification of patients suffering from Sjögren's syndrome, a complex and protean disease, leveraging a combination of clustering methods. Finally, the third part proposes a new computational deconvolution method for inferring the composition and individual characteristics of a heterogeneous set of cell populations, using bulk transcriptomic data in the absence of cytometry annotation. The proposed algorithm, DeCovarT, differs from gold-standard methods by explicitly including cross interactions in the form of gene regulatory networks into the statistical process of estimating cell ratios. To do so, we considered a new generative model to reconstitute the observed resulting mixtures using a convolution of multivariate Gaussian distributions.

\end{abstract}

\begin{abstract}[Abrégé]

L’analyse transcriptomique dite globale consiste à quantifier l’ensemble des transcrits exprimées par un échantillon biologique, pour un temps, un individu et un tissu donné. Les technologies récentes de séquençage globale de l'ADN ont permis d'envisager une mise à l'échelle permettant le traitement automatique de volumes de données croissants, à haut débit, et pour un coût d'analyse de plus en plus réduit. Ces dernières ont notamment permis une meilleure compréhension des processus biologiques agissant sur l’évolution de maladies complexes et protéiformes, permettant d'envisager le développement d'une médecine toujours plus personnalisée et ciblée.


Ainsi, une part croissante de la recherche pré-clinique de nouvelles cibles thérapeutiques d'intérêt consiste à tenter d'expliquer les variations phénotypiques observées entre individus (par exemple, la réponse différentielle à un traitement) par les différences de profils d'expression transcriptomiques entre différents individus. Les fluctuations observées proviennent d'un entrelacs d'interactions entre des facteurs techniques et biologiques, dont un certain nombre ne sont pas évalués par le transcriptome (métabolome, génomique, ...) ou ne sont pas observés. Il peut alors être d'utile d'introduire une variable latente pour tenter d'expliquer des mécanismes biologiques cachés. D'autre part, les possibilités exploratoires offertes par les méthodes d'analyse du transcriptome \enquote{globales} sont entravées par leur nature même. En effet, en mesurant l'expression globale d'un ensemble de gènes, elles masquent l'hétérogénéité intrinsèque des milieux biologiques, en agrégeant les mesures transcriptomiques exprimées par de multiples populations cellulaires.  


Nous proposons dans ce manuscrit trois contributions majeures pour pallier aux limitations inhérentes de ces méthodes. La première partie présente un pipeline industriel d'analyse de données transcriptomiques, sous la forme d'une suite de progiciels internes codés en R, et visant à homogénéiser des pratiques d'analyse classiques et de normalisation des données au sein de ma compagnie. La deuxième partie présente un banc d'essai de progiciels R implémentant une méthode classique d'analyse non supervisée de la variabilité d'un ensemble d'observations, à savoir les modèles de mélange Gaussiens, ainsi qu'un cas d'application concret visant à établir une stratification de patients souffrant du syndrome de Sjögren, une maladie complexe et protéiforme. Finalement, la troisième partie propose une nouvelle méthode computationnelle de déconvolution pour inférer la composition et les caractéristiques individuelles d’un ensemble hétérogène de populations cellulaires, et ce uniquement en substituant des données de cytométrie absentes avec des données du transcriptome global. L'algorithme proposé, DeCovarT, se distingue notamment des méthodes standard par sa faculté à incorporer explicitement les réseaux de régulation des gènes dans le processus d'estimation des ratios cellulaires, en recourant à une convolution de lois Gaussiennes multivariées.
\end{abstract}
